{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why does a model consume more space after training?\n",
    "I have noticed that before training, the model size is small. But after training, its size becomes bigger.\n",
    "\n",
    "It can be observed from the file size when saving it to disk.\n",
    "\n",
    "You can look at the question here: https://stackoverflow.com/q/57058178/2593810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "import numpy as np\n",
    "import os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = kr.Sequential([\n",
    "        kr.layers.Dense(1000, 'relu', input_shape=(500,)),\n",
    "        kr.layers.Dense(1000, 'relu'),\n",
    "        kr.layers.Dense(1, 'sigmoid')\n",
    "    ])\n",
    "    model.compile('adam', 'binary_crossentropy', ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(filename):\n",
    "    print(f\"{filename} size: {os.path.getsize(filename) / 1024 / 1024:.3f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 1,503,001\n",
      "Trainable params: 1,503,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model_a.h5 size: 5.748 MiB\n"
     ]
    }
   ],
   "source": [
    "model_a = build_model()\n",
    "model_a.summary()\n",
    "fn = 'model_a.h5'\n",
    "model_a.save(fn)\n",
    "print_model_size(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y(x):\n",
    "    return (x[:, [100, 200, 300, 400]].sum(1) > 2).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random((10000, 500))\n",
    "x_test = np.random.random((2000, 500))\n",
    "y_train = create_y(x_train)\n",
    "y_test = create_y(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 5s 512us/sample - loss: 0.5887 - acc: 0.6672 - val_loss: 0.2988 - val_acc: 0.8920\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 3s 379us/sample - loss: 0.2613 - acc: 0.8850 - val_loss: 0.1835 - val_acc: 0.9270\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 3s 379us/sample - loss: 0.1957 - acc: 0.9153 - val_loss: 0.1744 - val_acc: 0.9220\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 4s 395us/sample - loss: 0.1417 - acc: 0.9413 - val_loss: 0.1274 - val_acc: 0.9470\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 3s 372us/sample - loss: 0.1284 - acc: 0.9464 - val_loss: 0.1563 - val_acc: 0.9230\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 3s 364us/sample - loss: 0.1577 - acc: 0.9313 - val_loss: 0.1393 - val_acc: 0.9390\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 3s 363us/sample - loss: 0.1401 - acc: 0.9403 - val_loss: 0.1368 - val_acc: 0.9360\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 3s 358us/sample - loss: 0.1217 - acc: 0.9476 - val_loss: 0.2715 - val_acc: 0.8800\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 3s 360us/sample - loss: 0.1355 - acc: 0.9427 - val_loss: 0.1444 - val_acc: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b1e866080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(x_train, y_train, validation_split=0.1, epochs=100, callbacks=[kr.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_a_trained.h5 size: 17.232 MiB\n"
     ]
    }
   ],
   "source": [
    "fn = 'model_a_trained.h5'\n",
    "model_a.save(fn)\n",
    "print_model_size(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_b.h5 size: 5.748 MiB\n"
     ]
    }
   ],
   "source": [
    "# copy weights of model A to model B\n",
    "model_b = build_model()\n",
    "model_b.set_weights(model_a.get_weights())\n",
    "fn = 'model_b.h5'\n",
    "model_b.save(fn)\n",
    "print_model_size(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = kr.models.load_model\n",
    "model_a = load_model('model_a_trained.h5')\n",
    "model_b = load_model('model_b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0855224913239479, 0.974]\n",
      "[0.12154238364100456, 0.9475]\n"
     ]
    }
   ],
   "source": [
    "print(model_a.evaluate(x_train, y_train, verbose=0))\n",
    "print(model_a.evaluate(x_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0855224913239479, 0.974]\n",
      "[0.12154238364100456, 0.9475]\n"
     ]
    }
   ],
   "source": [
    "print(model_b.evaluate(x_train, y_train, verbose=0))\n",
    "print(model_b.evaluate(x_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "You will see that both `model_a` and `model_b` give the same accuracy yet their disk space consumption is tremendously different.\n",
    "\n",
    "It's because the `.fit()` command stores data of the training process that is not used for prediction.\n",
    "\n",
    "In this case, the data that is being stored is the *previous gradients state* of the Adam optimizer. Space consumption varies from optimizer to optimizer.\n",
    "\n",
    "In the case of SGD, the space consumption would not be big as it does not store gradients data.\n",
    "\n",
    "So if you don't want to train the model anymore you should save it with `include_optimizer=False` to reduce disk space consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
