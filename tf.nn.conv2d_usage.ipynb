{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does conv2d work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:46.638872",
     "start_time": "2017-02-03T09:09:26.433905"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:46.663964",
     "start_time": "2017-02-03T09:09:46.644491"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d_v2 in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv2d_v2(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filters` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *\n",
      "                            filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types:\n",
      "        `half`, `bfloat16`, `float32`, `float64`.\n",
      "        A 4-D tensor. The dimension order is interpreted according to the value\n",
      "        of `data_format`, see below for details.\n",
      "      filters: A `Tensor`. Must have the same type as `input`.\n",
      "        A 4-D tensor of shape\n",
      "        `[filter_height, filter_width, in_channels, out_channels]`\n",
      "      strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n",
      "        stride of the sliding window for each dimension of `input`. If a single\n",
      "        value is given it is replicated in the `H` and `W` dimension. By default\n",
      "        the `N` and `C` dimensions are set to 1. The dimension order is determined\n",
      "        by the value of `data_format`, see below for details.\n",
      "      padding: Either the `string` `\"SAME\"` or `\"VALID\"` indicating the type of\n",
      "        padding algorithm to use, or a list indicating the explicit paddings at\n",
      "        the start and end of each dimension. When explicit padding is used and\n",
      "        data_format is `\"NHWC\"`, this should be in the form `[[0, 0], [pad_top,\n",
      "        pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n",
      "        and data_format is `\"NCHW\"`, this should be in the form `[[0, 0], [0, 0],\n",
      "        [pad_top, pad_bottom], [pad_left, pad_right]]`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`.\n",
      "        Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, height, width, channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, channels, height, width].\n",
      "      dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n",
      "        defaults to 1. The dilation factor for each dimension of`input`. If a\n",
      "        single value is given it is replicated in the `H` and `W` dimension. By\n",
      "        default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n",
      "        will be k-1 skipped cells between each filter element on that dimension.\n",
      "        The dimension order is determined by the value of `data_format`, see above\n",
      "        for details. Dilations in the batch and depth dimensions if a 4-d tensor\n",
      "        must be 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the convolved result the sum or the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a ones-filled 3 by 3 image and the kernel with same size.\n",
    "\n",
    "We will try to convolve and see if the result will be 9 or 1.\n",
    "\n",
    "if the result is 9, it means that the resulting filter is just a `sum` not the `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:46.853181",
     "start_time": "2017-02-03T09:09:46.667519"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "img = tf.ones([1, 3, 3, 1]) # [N, H, W, C] shape\n",
    "kernel = tf.ones([3, 3, 1, 1]) # [H, W, in_C, out_C] shape\n",
    "strides = [1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the image before convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:48.251192",
     "start_time": "2017-02-03T09:09:46.857088"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.numpy().reshape([3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:48.630119",
     "start_time": "2017-02-03T09:09:48.254429"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.conv2d(img, kernel, strides, padding='VALID').numpy().reshape([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What values are padded with SAME padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After convolution again but now with `\"SAME\"` padding. Notice that edges are padded with zeros before convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:09:48.751323",
     "start_time": "2017-02-03T09:09:48.641245"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 6., 4.],\n",
       "       [6., 9., 6.],\n",
       "       [4., 6., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.conv2d(img, kernel, strides, padding='SAME').numpy().reshape([3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is the center of a kernel that has even size?\n",
    "An even size kernel is 2x2, 4x4 or 6x6, etc.\n",
    "We gonna find out by convolving a 3x3 image with a 2x2 kernel with SAME padding.\n",
    "\n",
    "The concept of kernel center is not required in VALID padding, but it's required in SAME padding.\n",
    "\n",
    "The concept of kernel center can also be replaced by topleft-padded or bottomright-padded concept.\n",
    "\n",
    "If the image is padded with zeros on the right side it will be similar to thinking of the kernel center as being on the left side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-03T09:14:36.448351",
     "start_time": "2017-02-03T09:14:36.417484"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 2.],\n",
       "       [4., 4., 2.],\n",
       "       [2., 2., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.ones([1, 3, 3, 1])\n",
    "kernel = tf.ones([2, 2, 1, 1])\n",
    "tf.nn.conv2d(img, kernel, strides, padding='SAME').numpy().reshape([3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "`conv2d` returns the `sum` not the `mean`. So it is different from this video (the video uses the mean): https://youtu.be/FmpDIaiMIeA?t=363\n",
    "\n",
    "`\"SAME\"` padding pads boundary edges with zeros and returns an image of the same size.\n",
    "\n",
    "The center of an even size kernel is at the up-left corner.\n",
    "(I'm not saying that it's the top-leftmost,\n",
    "it's kinda in the center. But in an even size kernel there is no actual center so it had to choose one that is up-left)\n",
    "\n",
    "You can also think of the image as being padded by zeros on the bottom and right side.\n",
    "But I prefer the center concept as it's easier to reason about for bigger kernel like 4x4 or 6x6.\n",
    "\n",
    "In bigger kernels, you will have to rethink the concept of padding. Because both sides will have to pad, but one side will pad more than the other."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
